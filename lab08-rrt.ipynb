{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import kdtree\n",
    "from statistics import mean\n",
    "import pandas as pd\n",
    "from tests.read_test_map import read_test_map\n",
    "from visualization.map_visualization import show_map_vectorized\n",
    "from visualization.rrt_visualization import visualize_rrt\n",
    "from tests.check_results import construct_path_from_node\n",
    "from utils.node import RRTNode\n",
    "from shapely.geometry import Polygon as ShapelyPolygon, Point, LineString\n",
    "from typing import List, Tuple, Union, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](./media/tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling-Based алгоритм RRT для задачи поиска пути\n",
    "В данной лабораторной работе мы изучим задачу поиска пути в непрерывном пространстве для агента-робота, используя подход на основе сэмплирования. Основной метод, который мы будем рассматривать, — это алгоритм Rapidly-exploring Random Tree (RRT), широко применяемый для планирования траекторий в сложных конфигурационных пространствах.\n",
    "\n",
    "Алгоритм RRT опирается на построение специальной структуры данных — дерева, которое быстро охватывает область поиска за счет последовательного добавления новых узлов. Каждый узел дерева, за исключением корня, имеет ровно одного родителя. На каждом шаге алгоритм генерирует новый узел и пытается присоединить его к существующему дереву. Конечная цель заключается в том, чтобы достичь области, близкой к целевой точке, посредством последовательного расширения дерева.\n",
    "\n",
    "Процесс расширения дерева RRT можно описать следующим образом:\n",
    "\n",
    "1) **Генерация случайной точки:** выбрать случайную точку x<sub>rand</sub> пространстве.  \n",
    "2) **Поиск ближайшего узла:** найти узел x<sub>near</sub> в текущем дереве, ближайший к точке x<sub>rand</sub> \n",
    "3) **Расширение дерева:** создать новый узел x<sub>new</sub> в направлении от точки x<sub>near</sub> к x<sub>rand</sub>.  \n",
    "\n",
    "Преимущество алгоритмов RRT и других методов на основе сэмплинга заключается в их применимости для задач поиска пути в непрерывных пространствах с учетом различных ограничений — геометрических (например, форма и размеры агента) и кинематических (ограничения на скорость и ускорение). Эти методы особенно эффективны при решении задач высокой размерности, таких как планирование движений манипуляторов.\n",
    "\n",
    "Однако в данной лабораторной работе мы сосредоточимся на ключевых идеях алгоритмов на основе сэмплинга, применяя их к задаче поиска пути на двумерной плоскости."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Представление пространства\n",
    "\n",
    "Для моделирования задачи поиска пути и построения дерева RRT в этой лабораторной работе используется двумерное пространство, в котором могут находиться препятствия, заданные в виде многоугольников.\n",
    "\n",
    "## Описание препятствий\n",
    "\n",
    "Препятствия определяются как наборы вершин многоугольников. Каждое препятствие представлено списком координат вершин в формате *(x, y)*. Например, список `obstacles_sample` содержит два препятствия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "obstacles_sample = [[(2, 2), (3, 3), (2, 4), (1, 3)],\n",
    "                    [(5, 5), (6, 7), (7, 6)],\n",
    "                    ]\n",
    "\n",
    "show_map_vectorized(10, 10, obstacles_sample, show_cords=False, show_obstacles_index=True, show_vertexes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## RRTNode и KDTree\n",
    "Алгоритм RRT строит дерево поиска, сэмплируя новые состояния и пытаясь соединить их с уже существующими узлами дерева. Одной из ключевых операций в процессе работы алгоритма является поиск ближайшего узла дерева к новому, только что сэмплированному состоянию. Эта операция будет выполняться многократно и желательно реализовать её эффективно.\n",
    "\n",
    "Для реализации данной задачи мы будем использовать внешний модуль `kdtree`, который предоставляет структуру данных — [k-d-дерево](https://ru.wikipedia.org/wiki/K-d-дерево). K-d-дерево позволяет эффективно выполнять операции добавления элементов и поиска ближайших соседей с хорошей асимптотикой:\n",
    "\n",
    "* Добавление элемента: **O(h)**  \n",
    "* Поиск ближайшего соседа: **O(h) * (O(log(h)) + 1)**    \n",
    "\n",
    "Где h — это высота дерева.\n",
    "### Структура узлов дерева — RRTNode\n",
    "Для заполнения дерева мы будем использовать объекты типа `RRTNode`. Каждый такой объект представляет собой узел дерева поиска, который хранит в себе следующую информацию:\n",
    "* Координаты точки в пространстве (поле `state`)\n",
    "* Ссылку на родительский узел (поле `parent`)\n",
    "* Длина пути от корневого узла до текущего (поле `g`)\n",
    "\n",
    "### Пример работы с RRTNode и KDTree\n",
    "Для начала создадим корень дерева `RRTNode`, представляющий начальное состояние:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RRTNode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_node = RRTNode(state=(0, 0), parent=None, g=0)  # Создание корня дерева\n",
    "tree = kdtree.create([root_node])  # Создание дерева KDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затем добавим в дерево несколько новых узлов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cords = [(0, 1), (1, 2), (3, 5), (4, 2)]  # Набор координат новых узлов\n",
    "for cord in cords:\n",
    "    tree.add(RRTNode(state=cord, parent=root_node))  # Добавление новых вершин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно найти ближайший узел к произвольной точке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ближайший узел: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "state_query = (2, 3)  # Состояние, для которого ищем ближайший узел\n",
    "nearest_node = tree.search_nn(state_query)[0].data  # Поиск ближайшего узла\n",
    "print(\"Ближайший узел:\", nearest_node.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_collision(state: Tuple[float, float], obstacles) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, есть ли пересечение между заданным состоянием и препятствиями.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты состояния (x, y).\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние пересекается с каким-либо препятствием, иначе False.\n",
    "    \"\"\"\n",
    "    # тут кажется была бага связанная с типом \n",
    "    point = Point(state)\n",
    "    for obs in obstacles:\n",
    "        if ShapelyPolygon(obs).contains(point):\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "\n",
    "def distance(state1: Tuple[float, float], state2: Tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Вычисляет расстояние между двумя состояниями в пространстве.\n",
    "\n",
    "    В данной лабораторной работе используется евклидово расстояние между точками на плоскости.\n",
    "\n",
    "    Args:\n",
    "        state1: Координаты первого состояния.\n",
    "        state2: Координаты второго состояния.\n",
    "\n",
    "    Return:\n",
    "        float: Евклидово расстояние между двумя состояниями.\n",
    "    \"\"\"\n",
    "    return math.sqrt(abs(state1[0] - state2[0]) ** 2 + abs(state1[1] - state2[1]) ** 2)\n",
    "\n",
    "\n",
    "def in_goal_region(state: Tuple[float, float], state_goal: Tuple[float, float], region_size: float) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, находится ли заданное состояние в пределах допустимого расстояния от целевого состояния.\n",
    "\n",
    "    Args:\n",
    "        state: Координаты проверяемого состояния.\n",
    "        state_goal: Координаты целевого состояния.\n",
    "        region_size: Радиус области, в пределах которой состояние считается достижением цели.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если состояние находится в пределах области цели, иначе False.\n",
    "    \"\"\"\n",
    "    return distance(state, state_goal) <= region_size\n",
    "    \n",
    "\n",
    "def is_trajectory_clear(start_state: Tuple[float, float], end_state: Tuple[float, float], obstacles: List[ShapelyPolygon]) -> bool:\n",
    "    \"\"\"\n",
    "    Проверяет, пересекает ли траектория, задаваемая начальным и конечным состояниями, какие-либо препятствия.\n",
    "\n",
    "    Args:\n",
    "        start_state: Координаты начального состояния.\n",
    "        end_state: Координаты конечного состояния.\n",
    "        obstacles: Список препятствий.\n",
    "\n",
    "    Return:\n",
    "        bool: True, если траектория свободна от пересечений, иначе False.\n",
    "    \"\"\"\n",
    "    for obs in obstacles:\n",
    "        if LineString([start_state, end_state]).intersects(ShapelyPolygon(obs)):\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def create_random_state(map_width: float, map_height: float, \n",
    "                        goal_bias: float, goal_state: Tuple[float, float], \n",
    "                        goal_sampling_region: float) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Генерирует случайное состояние в пространстве поиска.\n",
    "\n",
    "    С вероятностью `goal_bias` возвращает состояние в окрестности цели в пределах размера области `goal_sampling_region` \n",
    "    (любое, можно саму цель всегда возвращать). \n",
    "    В противном случае генерирует равномерно случайное состояние в пределах карты.\n",
    "\n",
    "    Args:\n",
    "        map_width: Ширина карты.\n",
    "        map_height: Высота карты.\n",
    "        goal_bias: Вероятность генерации состояния около цели.\n",
    "        goal_state: Координаты целевого состояния.\n",
    "        goal_sampling_region: Размер области около цели.\n",
    "\n",
    "    Return:\n",
    "        tuple[float, float]: Случайное состояние (x, y).\n",
    "    \"\"\"\n",
    "    if random.random() < goal_bias:\n",
    "        # здесь возвращается в пределах кварата а не круга... хз какой вариант нужен был\n",
    "        offset_x = random.uniform(-goal_sampling_region, goal_sampling_region)\n",
    "        offset_y = random.uniform(-goal_sampling_region, goal_sampling_region)\n",
    "        \n",
    "        x = goal_state[0] + offset_x\n",
    "        y = goal_state[1] + offset_y\n",
    "        \n",
    "        x = max(0, min(map_width, x))\n",
    "        y = max(0, min(map_height, y))\n",
    "\n",
    "        return (x, y)\n",
    "    else:\n",
    "        x = random.uniform(0, map_width)\n",
    "        y = random.uniform(0, map_height)\n",
    "        return (x, y)\n",
    "\n",
    "\n",
    "def find_nearest_neighbour(tree: kdtree, state_random: Tuple[float, float]) -> RRTNode:\n",
    "    \"\"\"\n",
    "    Находит ближайший узел в дереве поиска к заданному случайному состоянию.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "\n",
    "    Return:\n",
    "        RRTNode: Ближайший узел в дереве к заданному состоянию.\n",
    "    \"\"\"\n",
    "    return tree.search_nn(state_random)[0].data  \n",
    "\n",
    "\n",
    "def extend(tree: kdtree, obstacles: List[ShapelyPolygon], \n",
    "           state_random: Tuple[float, float], \n",
    "           max_transition: float) -> Tuple[bool, Optional[RRTNode]]:\n",
    "    \"\"\"\n",
    "    Расширяет дерево поиска, пытаясь создать новое состояние в направлении заданного случайного состояния\n",
    "    (проверяется точка, находящаяся на расстоянии минимума из расстояния до ближайшего соседа и `max_transition`).\n",
    "\n",
    "    Если новое состояние валидно и не пересекается с препятствиями, оно добавляется в дерево.\n",
    "\n",
    "    Args:\n",
    "        tree: KD-дерево, представляющее текущее дерево поиска.\n",
    "        obstacles: Список препятствий в пространстве.\n",
    "        state_random: Случайно сгенерированное состояние.\n",
    "        max_transition: Максимально допустимое расстояние перехода.\n",
    "\n",
    "    Return:\n",
    "        tuple[bool, Optional[RRTNode]]: \n",
    "            - Флаг успешного добавления нового состояния.\n",
    "            - Новый узел, если состояние было добавлено, иначе None.\n",
    "\n",
    "    ! Не забудьте при составлении RRTNode указать его родителя и стоимость перехода в него\n",
    "    \"\"\"\n",
    "    nearest_node = find_nearest_neighbour(tree, state_random)\n",
    "    nearest_state = nearest_node.state\n",
    "    needed_distance = min(max_transition, distance(nearest_node.state, state_random))\n",
    "    \n",
    "    if needed_distance > 0: \n",
    "        direction_x = (state_random[0] - nearest_node.state[0]) / needed_distance\n",
    "        direction_y = (state_random[1] - nearest_node.state[1]) / needed_distance\n",
    "\n",
    "        new_state = (\n",
    "            nearest_node.state[0] + direction_x * needed_distance,\n",
    "            nearest_node.state[1] + direction_y * needed_distance\n",
    "        )\n",
    "    else:\n",
    "        # если они совпали то добавлять ничего не надо  \n",
    "        return (False, None)\n",
    "    \n",
    "    # если она в препятсвии \n",
    "    if in_collision(new_state, obstacles):\n",
    "        return (False, None)\n",
    "\n",
    "    # если есть припятсвие по пути\n",
    "    if not is_trajectory_clear(nearest_node.state, new_state, obstacles):\n",
    "        return (False, None)\n",
    "    \n",
    "    # добавляем в дерево если все оки \n",
    "    new_g = nearest_node.g + distance(nearest_node.state, new_state)\n",
    "    new_node = RRTNode(new_state, nearest_node, new_g)\n",
    "    tree.add(new_node)\n",
    "\n",
    "    return (True, new_node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Основной алгоритм RRT\n",
    "\n",
    "Функция `rrt` собирает вместе весь функционал алгоритма поиска пути. На каждом шаге алгоритм выполняет следующие действия:\n",
    "\n",
    "1. Генерирует случайное состояние с помощью `create_random_state`.\n",
    "\n",
    "2. Расширяет дерево с помощью функции `extend`. \n",
    "\n",
    "3. Проверяет, достиг ли алгоритм целевой области.\n",
    "\n",
    "Если цель достигнута или превышено максимальное количество итераций, функция завершает свою работу.\n",
    "\n",
    "\n",
    "Обратите внимание! Сохраняйте все добавленные узлы в список `all_points`, чтобы впоследствии визуализировать процесс построения дерева.\n",
    "Также не забывайте пополнять ими дерево через `tree.add(...)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rrt(map_w: int,\n",
    "        map_h: int,\n",
    "        obstacles: List[List[float]], \n",
    "        start_x: float, \n",
    "        start_y: float, \n",
    "        goal_x: float, \n",
    "        goal_y: float, \n",
    "        max_transition: float,\n",
    "        max_iter: int = 3000, \n",
    "        goal_region: float = 5,\n",
    "        goal_bias: float = 0.05\n",
    "        ) -> Tuple[bool, Optional['RRTNode'], int, Optional['kdtree.KDTree'], List[Tuple['RRTNode', int]]]:\n",
    "    \"\"\"\n",
    "    Реализует алгоритм поиска RRT.\n",
    "\n",
    "    Args:\n",
    "        map_w: Ширина карты.\n",
    "        map_h: Высота карты.\n",
    "        obstacles: Список препятствий на карте.\n",
    "        start_x: Координата x начальной точки.\n",
    "        start_y: Координата y начальной точки.\n",
    "        goal_x: Координата x цели.\n",
    "        goal_y: Координата y цели.\n",
    "        max_transition: Максимальное расстояние, на которое может перемещаться агент за один шаг.\n",
    "        max_iter: Максимальное количество итераций алгоритма.\n",
    "        goal_region: Размер окрестности целевого состояния, в которой цель считается достигнутой.\n",
    "        goal_bias: Вероятность сэмплинга состояния, близкого к цели.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[bool, Optional[RRTNode], int, Optional[kdtree.KDTree], List[RRTNode]]:\n",
    "            - Булевое значение, указывающее, был ли найден путь.\n",
    "            - Последний узел найденного пути или None, если путь не был найден.\n",
    "            - Количество итераций, выполненных алгоритмом.\n",
    "            - KD-дерево, представляющее дерево поиска, или None, если путь не найден.\n",
    "            - Список всех узлов, добавленных в дерево, в порядке добавления, а также итерация на которой узел был добавлен\n",
    "    \"\"\"\n",
    "    \n",
    "    node_start = RRTNode([start_x, start_y], None, 0.0)\n",
    "    state_goal = [goal_x, goal_y]\n",
    "    tree = kdtree.create([node_start])\n",
    "    iter = 0\n",
    "    all_points = [(node_start, 0)] # тут хранятся пары из вершин (RRTNode) и номера итерации на котором их добавили\n",
    "    \n",
    "    for iter in range(1, max_iter + 1):\n",
    "\n",
    "        # генерируем рандом состяние \n",
    "        state_random = create_random_state(\n",
    "            map_w, map_h, goal_bias, state_goal, goal_region\n",
    "        )\n",
    "\n",
    "        # пытаемсяя добавить ноду в дерево\n",
    "        correct, new_node = extend(\n",
    "            tree, obstacles, state_random, max_transition\n",
    "        )\n",
    "\n",
    "        if not correct:\n",
    "            continue\n",
    "\n",
    "        all_points.append((new_node, iter))\n",
    "\n",
    "        # проверяем добавленную ноду на попадание\n",
    "        if in_goal_region(new_node.state, state_goal, goal_region):\n",
    "            return (True, new_node, iter, tree, all_points)\n",
    "        \n",
    "    return (False, None, max_iter, tree, all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./media/maps.png\" alt=\"drawing\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test\n",
    "Предварительный тест для проверки всё ли у вас правильно работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=5, goal_bias=0.05, goal_region=5)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=5, iterations=number_of_steps, max_iteration=1000, path_length=42)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=end_node.g)\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Obstacles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "width, height, start, goal, obstacles = read_test_map(\"./tests/rand_polygons.txt\")\n",
    "found, end_node, number_of_steps, tree, all_points = rrt(width, height, obstacles, *start, *goal, max_transition=7, goal_bias=0.05, goal_region=10)\n",
    "assert found, \"`found` должно быть True - иначе пробуйте ещё раз или что-то реализовано неверно\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = visualize_rrt(width, height, *start, *goal, obstacles, all_points, construct_path_from_node(end_node), goal_region=10, iterations=number_of_steps, max_iteration=10_000, path_length=round(end_node.g,2))\n",
    "animation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Massive Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 116, Nodes: 49\n",
      "Avg steps: 193\n",
      "Avg nodes: 88.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 136, Nodes: 48\n",
      "Avg steps: 184.2\n",
      "Avg nodes: 73\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 16, Nodes: 10\n",
      "Avg steps: 146.6\n",
      "Avg nodes: 48\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 503, Nodes: 223\n",
      "Avg steps: 298.6\n",
      "Avg nodes: 125.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 218, Nodes: 85\n",
      "Avg steps: 169.6\n",
      "Avg nodes: 65.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 369, Nodes: 126\n",
      "Avg steps: 276\n",
      "Avg nodes: 98\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 97, Nodes: 36\n",
      "Avg steps: 91.8\n",
      "Avg nodes: 29.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 58, Nodes: 28\n",
      "Avg steps: 108.4\n",
      "Avg nodes: 38.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 3\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 43, Nodes: 14\n",
      "Avg steps: 77.6\n",
      "Avg nodes: 27.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 201, Nodes: 84\n",
      "Avg steps: 162.4\n",
      "Avg nodes: 73.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 42, Nodes: 19\n",
      "Avg steps: 143\n",
      "Avg nodes: 57.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 131, Nodes: 61\n",
      "Avg steps: 184.4\n",
      "Avg nodes: 65.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 86, Nodes: 40\n",
      "Avg steps: 235\n",
      "Avg nodes: 93.4\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 144, Nodes: 53\n",
      "Avg steps: 166.6\n",
      "Avg nodes: 60.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 164, Nodes: 58\n",
      "Avg steps: 167.8\n",
      "Avg nodes: 59.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 154, Nodes: 60\n",
      "Avg steps: 91.6\n",
      "Avg nodes: 34\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 91, Nodes: 33\n",
      "Avg steps: 100.8\n",
      "Avg nodes: 33.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 7\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 137, Nodes: 51\n",
      "Avg steps: 87.2\n",
      "Avg nodes: 30.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 246, Nodes: 104\n",
      "Avg steps: 272.4\n",
      "Avg nodes: 113.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 53, Nodes: 21\n",
      "Avg steps: 171\n",
      "Avg nodes: 64.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 5\n",
      "First run - Found: True, Steps: 166, Nodes: 59\n",
      "Avg steps: 277.4\n",
      "Avg nodes: 99.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 119, Nodes: 54\n",
      "Avg steps: 220.4\n",
      "Avg nodes: 101.6\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 123, Nodes: 58\n",
      "Avg steps: 138.4\n",
      "Avg nodes: 55\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 10\n",
      "First run - Found: True, Steps: 165, Nodes: 73\n",
      "Avg steps: 113.6\n",
      "Avg nodes: 46.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.05\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 92, Nodes: 30\n",
      "Avg steps: 62.2\n",
      "Avg nodes: 23.2\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.1\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 166, Nodes: 58\n",
      "Avg steps: 213\n",
      "Avg nodes: 72.8\n",
      "Success rate: 1.00\n",
      "-----------------\n",
      "Max transition: 15\n",
      "Goal bias: 0.15\n",
      "Goal region: 25\n",
      "First run - Found: True, Steps: 147, Nodes: 56\n",
      "Avg steps: 105.8\n",
      "Avg nodes: 34.4\n",
      "Success rate: 1.00\n",
      " max_transition  goal_bias  goal_region  first_run_found  first_run_steps  first_run_nodes  avg_steps  avg_nodes  success_rate\n",
      "              3       0.05            5             True              116               49      193.0       88.2           1.0\n",
      "              3       0.10            5             True              136               48      184.2       73.0           1.0\n",
      "              3       0.15            5             True               16               10      146.6       48.0           1.0\n",
      "              3       0.05           10             True              503              223      298.6      125.2           1.0\n",
      "              3       0.10           10             True              218               85      169.6       65.4           1.0\n",
      "              3       0.15           10             True              369              126      276.0       98.0           1.0\n",
      "              3       0.05           25             True               97               36       91.8       29.4           1.0\n",
      "              3       0.10           25             True               58               28      108.4       38.8           1.0\n",
      "              3       0.15           25             True               43               14       77.6       27.2           1.0\n",
      "              7       0.05            5             True              201               84      162.4       73.4           1.0\n",
      "              7       0.10            5             True               42               19      143.0       57.2           1.0\n",
      "              7       0.15            5             True              131               61      184.4       65.2           1.0\n",
      "              7       0.05           10             True               86               40      235.0       93.4           1.0\n",
      "              7       0.10           10             True              144               53      166.6       60.2           1.0\n",
      "              7       0.15           10             True              164               58      167.8       59.2           1.0\n",
      "              7       0.05           25             True              154               60       91.6       34.0           1.0\n",
      "              7       0.10           25             True               91               33      100.8       33.8           1.0\n",
      "              7       0.15           25             True              137               51       87.2       30.6           1.0\n",
      "             15       0.05            5             True              246              104      272.4      113.2           1.0\n",
      "             15       0.10            5             True               53               21      171.0       64.8           1.0\n",
      "             15       0.15            5             True              166               59      277.4       99.8           1.0\n",
      "             15       0.05           10             True              119               54      220.4      101.6           1.0\n",
      "             15       0.10           10             True              123               58      138.4       55.0           1.0\n",
      "             15       0.15           10             True              165               73      113.6       46.2           1.0\n",
      "             15       0.05           25             True               92               30       62.2       23.2           1.0\n",
      "             15       0.10           25             True              166               58      213.0       72.8           1.0\n",
      "             15       0.15           25             True              147               56      105.8       34.4           1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "max_transitions = [3, 7, 15]\n",
    "goal_regions = [5, 10, 25]\n",
    "goal_biases = [0.05, 0.10, 0.15]\n",
    "num_runs = 5 \n",
    "\n",
    "width, height, start, goal, obstacles = read_test_map(\"./tests/columns_small.txt\")\n",
    "results = []\n",
    "\n",
    "for max_transition in max_transitions:\n",
    "    for goal_region in goal_regions:\n",
    "        for goal_bias in goal_biases:\n",
    "            run_results = []\n",
    "            for _ in range(num_runs):\n",
    "                found, end_node, number_of_steps, tree, all_points = rrt(\n",
    "                    width, height, obstacles, *start, *goal, \n",
    "                    max_transition=max_transition, goal_bias=goal_bias, goal_region=goal_region\n",
    "                )\n",
    "                run_results.append({\"found\": found, \n",
    "                                    \"number_of_steps\": number_of_steps, \n",
    "                                    \"number_of_nodes\": len(all_points)})\n",
    "\n",
    "            first_run = run_results[0]\n",
    "\n",
    "            avg_steps = mean(run[\"number_of_steps\"] for run in run_results)\n",
    "            avg_nodes = mean(run[\"number_of_nodes\"] for run in run_results)\n",
    "            success_rate = sum(run[\"found\"] for run in run_results) / num_runs\n",
    "\n",
    "            results.append({\n",
    "                \"max_transition\": max_transition,\n",
    "                \"goal_bias\": goal_bias,\n",
    "                \"goal_region\": goal_region,\n",
    "                \"first_run_found\": first_run[\"found\"],\n",
    "                \"first_run_steps\": first_run[\"number_of_steps\"],\n",
    "                \"first_run_nodes\": first_run[\"number_of_nodes\"],\n",
    "                \"avg_steps\": avg_steps,\n",
    "                \"avg_nodes\": avg_nodes,\n",
    "                \"success_rate\": success_rate\n",
    "            })\n",
    "            line = results[-1]\n",
    "            print(\"-----------------\")\n",
    "            print(f\"Max transition: {line['max_transition']}\")\n",
    "            print(f\"Goal bias: {line['goal_bias']}\")\n",
    "            print(f\"Goal region: {line['goal_region']}\")\n",
    "            print(f\"First run - Found: {line['first_run_found']}, Steps: {line['first_run_steps']}, Nodes: {line['first_run_nodes']}\")\n",
    "            print(f\"Avg steps: {line['avg_steps']}\")\n",
    "            print(f\"Avg nodes: {line['avg_nodes']}\")\n",
    "            print(f\"Success rate: {line['success_rate']:.2f}\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (lab08-rrt)",
   "language": "python",
   "name": "lab08-rrt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
